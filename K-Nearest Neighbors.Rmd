
## Credit Approval Data Set
The dataset is the “Credit Approval Data Set” from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Credit+Approval) without the categorical variables and without data points that have missing values.

This model follows up the Support Vector Machine model that worked on this dataset.

Setting up by calling relevant libraries and opening data file and assigning to mydata variable:

```{r set up, results='hide}
library(kknn)
library(data.table)
mydata <- read.table('credit_card_data-headers.txt',header = TRUE)
```

Creating a fucntion that would return an accuracy level for a given k value:

```{r function, results='hide'}

accuracy_calc = function(x){
  prediction <- rep(0,(nrow(mydata)))
  
  for (i in 1:nrow(mydata)){
    model=kknn(R1~A1+A2+A3+A8+A9+A10+A11+A12+A14+A15,mydata[-i,],mydata[i,],k=x, distance = 2, kernel = 'optimal', scale = TRUE)
    
    prediction[i] <- as.integer(fitted(model)+0.5)
  }
  
  knn_accuracy = sum(prediction == mydata[,11]) / nrow(mydata)
  return(knn_accuracy)
}
```

Now I set up a range of k values to test with:

``` {r k_range}
accurracy_range = rep(0,40) # set up a vector of 20 zeros to start

for (x in 1:40){
  accurracy_range[x] = accuracy_calc(x)
}
```
Let's plot the accuracy measurement against the number of k:

``` {r plotk}
plot(accurracy_range,xlab='Value of k',ylab ='Accuracy Level')
```
Then, I find the highest accuracy level produced:

``` {r max_accuracy}
max(accurracy_range)
```
Then I get the corresponding k value:

``` {r best_k}
which.max(accurracy_range)
```

As we can see, for the 'optimal' kernel in kknn model, a k value of 12 (12 nearest neighbors) would yield the best prediction for the credit card approval data at 85.32%.


